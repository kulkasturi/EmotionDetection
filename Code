import numpy as np
import cv2
import os
import random
from skimage.io import imread
import pandas as pd
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Activation
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt
from IPython.display import Audio

!pip install kaggel

from google.colab import files
files.upload()
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle datasets list
! kaggle datasets download -d msambare/fer2013
!unzip fer2013.zip

train_dir = r'/content/train'
test_dir = r'/content/test'

row, col = 48,48
classes = 7

def count_exp(path, set_):
  dict_ = {}
  for expression in os.listdir(path):
    dir_ = path + "/" + expression
    dict_[expression] = len(os.listdir(dir_))
  df = pd.DataFrame(dict_, index=[set_])
  return df
train_count = count_exp(train_dir, 'train')
test_count = count_exp(test_dir, 'test')
print(train_count)
print(test_count)

#Data visualization
from skimage.io import imread
train_dir = "/content/train/"
test_dir = "/content/test/"
total_labels = len(os.listdir(train_dir))

fig, ax = plt.subplots(nrows = 5, ncols=total_labels, figsize=(35,25))
for x in range(5):
  for y,v in zip(range(total_labels),os.listdir(train_dir)):
    ax[x][y].imshow(imread(train_dir+v+'/'+os.listdir(train_dir+v)[x]),cmap='gray')

plt.show()

df = {}
for i in os.listdir(train_dir):
  directory = train_dir + i
  df[i] = len(os.listdir(directory))
df = pd.DataFrame(df, index = ["total"]).transpose().sort_values("total", ascending = False)

plt.figure(figsize=(15,7))
sns.barplot(x=df.index, y="total", palette="mako", data= df)
plt.ylabel("count")
plt.title("Total images of each label in train dataset")
plt.show()

happy = os.listdir(train_dir+'happy/')
dim1, dim2 = [], []

for img_filename in happy:
  img = imread(train_dir + 'happy/'+ img_filename)
  d1,d2 = img.shape
  dim1.append(d1)
  dim2.append(d2)

  img_shape = (int(np.mean(dim1)), int(np.mean(dim2)), 1)
  sns.jointplot(dim1  ,  color='g')
  plt.show()

#Data preprocessing

train_gen = ImageDataGenerator(rescale =1/255,
                               rotation_range=40,
                               width_shift_range=0.2,
                               shear_range=0.2,
                               zoom_range=0.2,
                               horizontal_flip=True,
                               fill_mode='nearest')

test_gen = ImageDataGenerator(rescale = 1/255)

img_shape = (int(np.mean(dim1)),int(np.mean(dim2)),1)

train_generator = train_gen.flow_from_directory(directory=train_dir,
                                                target_size=(img_shape[0], img_shape[1]),
                                                color_mode='grayscale',
                                                batch_size=64,
                                                class_mode='categorical',
                                                shuffle=True)

test_generator = test_gen.flow_from_directory(directory=test_dir,
                                                target_size=(img_shape[0], img_shape[1]),
                                                color_mode='grayscale',
                                                batch_size=64,
                                                class_mode='categorical',
                                                shuffle=False)

model = Sequential()

model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', input_shape=img_shape))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))

model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))

model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))

model.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.2))

model.add(Flatten())

model.add(Dense(512, activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(units=len(os.listdir(train_dir)), activation='softmax'))

model.summary()

# Train the model
model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

steps_per_epoch = train_generator.n // train_generator.batch_size
validation_steps = test_generator.n // test_generator.batch_size
num_epochs = 5

history = model.fit(train_generator,
                    epochs=num_epochs,
                    verbose=1,
                    #callbacks=callbacks,
                    validation_data=test_generator,
                    steps_per_epoch=steps_per_epoch,
                    validation_steps=validation_steps)

model.save("model.h5")

test_loss, test_acc = model.evaluate(test_generator)
print("validation accuracy :", str(test_acc*100)+"%")
print("validation loss :", test_loss)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(acc))

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 6))
ax[0].plot(epochs, acc, 'g', label='Training accuracy')
ax[0].plot(epochs, val_acc, 'r', label='Validation accuracy')
ax[0].legend(loc=0)
ax[1].plot(epochs, loss, 'g', label='Training loss')
ax[1].plot(epochs, val_loss, 'r', label='Validation loss')
ax[1].legend(loc=0)

plt.suptitle('Training and validation')
plt.show()

# confusion matrix
from sklearn.metrics import classification_report, confusion_matrix

y_pred = np.argmax(model.predict(test_generator), axis=-1)
print(classification_report(test_generator.classes, y_pred, target_names=test_generator.class_indices.keys()), end='\n\n\n')

cm = confusion_matrix(test_generator.classes, y_pred)
plt.figure(figsize=(16,10))
sns.heatmap(cm, cmap=plt.cm.viridis, annot=True, fmt='.0f', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())
plt.show()

# Testing our model with new image
image = cv2.imread("/content/Training_438558.jpg")
from IPython.display import Image
Image(filename='/content/Training_438558.jpg')

import cv2
from tensorflow.python.keras.models import load_model
import os


# # load the trained model

model = tf.keras.models.load_model("model.h5",
    custom_objects={'Functional':tf.keras.models.Model})
# A list of emoticon categories
EMOTIONS = ['Angry' , 'Disgust',"Fear", 'Happy', 'Neutral', 'Sad', 'Surprise']
# Load image
img = image

# Trim the image to 48 x 48, and turn the grayscale image, normalization
frame = cv2.resize(img,(48,48),interpolation=cv2.INTER_BITS2)
gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) / 255.0
#print(gray)
print("---------------------")
# Reinvent the image dimension
gray = gray.reshape(1,48,48,1)

# Output the prediction
predicts = model.predict(gray)[0]
#print("Shape of predicts array:", predicts.shape)  # Add
#print(gray)
#print("Shape of predicts array:", predicts.argmax())
#print("Shape of predicts array:", predicts)
label = EMOTIONS[predicts.argmax()]
#print("Shape of predicts array:", predicts.argmax()-1)
for (i,j) in zip(range(7),EMOTIONS):
    predictss = predicts[i]
    print("{:^10s}".format(j)+"prediction rate is   {0:.2f}%".format(predictss))
print( "\n\n The system considers this expression to be:",label)

if (label=='Angry'):
    path="/content/Angry/"
    files=os.listdir(path)
    d=random.choice(files)
    print("Now Playing:",d)
    audio = Audio(filename='/content/Angry/'+ d,autoplay=True)
    display(audio)

elif (label=='Disgust'):
    path="/content/Fear/"
    files=os.listdir(path)
    d=random.choice(files)
    print("Now Playing:",d)
    audio = Audio(filename='/content/Fear/'+ d,autoplay=True)
    display(audio)

elif (label=="Happy"):
    path="/content/Happy/"
    files=os.listdir(path)
    d=random.choice(files)
    print("Now Playing:",d)
    audio = Audio(filename='/content/Happy/'+ d,autoplay=True)
    display(audio)

elif (label=='Sad'):
    path="/content/Sad/"
    files=os.listdir(path)
    d=random.choice(files)
    print("Now Playing:",d)
    audio = Audio(filename='/content/Sad/'+ d,autoplay=True)
    display(audio)

elif (label=='Surprise'):
    path="/content/Suprise/"
    files=os.listdir(path)
    d=random.choice(files)
    print("Now Playing:",d)
    audio = Audio(filename='/content/Suprise/'+ d,autoplay=True)
    display(audio)

elif (label=='Neutral'):
    path="/content/Neutral/"
    files=os.listdir(path)
    d=random.choice(files)
    print("Now Playing:",d)
    audio = Audio(filename='/content/Neutral/'+ d,autoplay=True)
    display(audio)
